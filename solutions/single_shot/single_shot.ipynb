{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dying-avenue",
   "metadata": {},
   "source": [
    "# One-Shot Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-workshop",
   "metadata": {},
   "source": [
    "\n",
    "BoonAI's One-Shot learning feature allows you to train a model with a single represenative example\n",
    "\n",
    "This jupyter notebook demonstrates the workflow used in the documentation for **Boon AI's Python SDK**. You can find that walk-through [here](https://app.gitbook.com/@zorroa/s/boonsdk/solutions/single-shot).<br>\n",
    "\n",
    "## Setup: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boonsdk\n",
    "\n",
    "# You must copy your API key into parent directory for it to be loaded.\n",
    "app = boonsdk.app_from_keyfile(\"../apikey.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-validation",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "Now that we have set up the environment, we can define the dataset. We will be using a sample set comprised of two resumes and two cover letters to train our model. Remember, a dataset is a collection of assets to which a label has been assigned. In order for a model to be trained, it must be attached to a dataset. For more information on datasets, refer to datasets subheading, under custom models in our documentation. You can find it [here](https://app.gitbook.com/@zorroa/s/boonsdk/training-models/datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset.  If you've already created this Dataset then you\n",
    "# can skip this step.\n",
    "app.datasets.create_dataset(\n",
    "    \"job-documents-dataset\", \n",
    "    boonsdk.DatasetType.Classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-humor",
   "metadata": {},
   "source": [
    " There is an images.csv file in this directory. It consists of two columns and five rows. The first row is a header. The first column points to the uri for an image and the second applies a label to that image. If you have downloaded this file, be sure to provide the path to your local version of \"images.csv\" By providing labels that we have already associated with the dataset we're creating, we are associating these images with the dataset. After running this next block of code, you will recieve an object enumerating errors, number of assets you have created, and number of assets that exist. If you see a number in 'exists', it means that you have attempted to upload a duplicate of a file already in your project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have downloaded this file, be sure to provide the path to your local version of \"images.csv\"\n",
    "path_to_csv = \"./images.csv\"\n",
    "\n",
    "\n",
    "# The file we're importing has values separated by commas, which is the default delimeter. \n",
    "# Each uri and label is enclosed in double quotes. \n",
    "csvfile = boonsdk.CsvFileImport(path_to_csv,\n",
    "                                uri_column=0,\n",
    "                                dataset=dataset,\n",
    "                                label_column=1,\n",
    "                                header=True)\n",
    "\n",
    "result = app.assets.import_csv(csvfile)\n",
    "\n",
    "# Wait on the import job to complete.\n",
    "app.jobs.wait_on_job(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-lightning",
   "metadata": {},
   "source": [
    "## Model:\n",
    "Now that we have a dataset imported, we can create and train a model that will predict the type of any future documents we add to this project. We will use a KNN Classifier and attach the dataset we created earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the dataset we made earlier.\n",
    "dataset = dataset=app.datasets.get_dataset(\"job-documents-dataset\")\n",
    "\n",
    "# Create model and link the dataset.\n",
    "model = app.models.create_model(\n",
    "    \"document-classifier\",\n",
    "    boonsdk.ModelType.KNN_CLASSIFIER,\n",
    "    dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-caution",
   "metadata": {},
   "source": [
    "## Training: \n",
    "The next step after creating a model with an attached dataset is to train the model. KNN Classifiers are relatively quick to train, so we shouldn't have to wait long for this step to be complete. You can use the job ID returned from the following line of code to check when the training is complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.models.train_model(model)\n",
    "\n",
    "# Wait on the training job to be done, this should take 10-20 seconds.\n",
    "app.jobs.wait_on_job(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-pledge",
   "metadata": {},
   "source": [
    "## Testing: \n",
    "Now we'll test the model we've trained by providing the url for a single image we would like to classify as either a resume or a cover letter. The result we print is a JSON object with one prediction comprised of a label and a confidence score. If the predicted label returned is 'Unrecognized', that means the model believes what you have provided is not a resume or a cover letter. \n",
    "**Note: this does not upload a new asset, it only analyzed an image you have referred to by url.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_resume1.jpg\", \"rb\") as fp:\n",
    "    result = app.assets.analyze_file(fp, [\"document-classifier\"])\n",
    "print(result.get_analysis(\"document-classifier\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-bubble",
   "metadata": {},
   "source": [
    "## Improving Performance\n",
    "There are many different styles of resumes and and you might eventually run into a case where your model fails to recognize the correct type of document.  When this happens you can improve your model's performance by labeling more examples and retraining your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
